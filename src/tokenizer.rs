use std::process;

use crate::tokens::{KEYWORD_MAP, Token};
use crate::utils::get_file_contents;

pub fn tokenize(filename: &str) -> (Vec<Token>, Vec<Token>) {
    eprintln!("Logs from your program will appear here!");

    let mut output: Vec<Token> = Vec::new();
    let mut errors: Vec<Token> = Vec::new();

    let file_contents = get_file_contents(filename);

    if !file_contents.is_empty() {
        for (i, line) in file_contents.lines().enumerate() {
            let mut tokens = line.chars().peekable();
            let line_number = i + 1;

            while let Some(token) = tokens.next() {
                let token = match token {
                    '(' => Token::LeftParen,
                    ')' => Token::RightParen,
                    '{' => Token::LeftBrace,
                    '}' => Token::RightBrace,
                    '.' => Token::Dot,
                    ',' => Token::Comma,
                    '+' => Token::Plus,
                    '-' => Token::Minus,
                    '*' => Token::Star,
                    ';' => Token::SemiColon,
                    '=' => get_equal_token(&mut tokens, Token::EqualEqual, Token::Equal),
                    '!' => get_equal_token(&mut tokens, Token::BangEqual, Token::Bang),
                    '>' => get_equal_token(&mut tokens, Token::GreaterEqual, Token::Greater),
                    '<' => get_equal_token(&mut tokens, Token::LessEqual, Token::Less),
                    '/' => match tokens.peek().copied() {
                        Some('/') => break,
                        _ => Token::Division,
                    },
                    ' ' | '\n' | '\t' => {
                        continue;
                    }
                    '"' => get_string_token(&mut tokens, line_number),
                    number if token.is_numeric() => {
                        get_numeric_token(&mut tokens, number, line_number)
                    }
                    identifier if token.is_alphabetic() || token == '_' => {
                        get_identifier(&mut tokens, identifier, line_number)
                    }
                    _ => Token::Error(token, line_number),
                };

                match token {
                    Token::ErrorString(_, _) | Token::Error(_, _) => {
                        errors.push(token);
                    }
                    _ => {
                        output.push(token);
                    }
                }
            }
        }
    }

    (output, errors)
}

pub fn print_tokens(output: Vec<Token>, errors: Vec<Token>) {
    let has_errors = !errors.is_empty();

    for token in errors {
        eprintln!("{}", token);
    }

    for token in output {
        println!("{}", token);
    }

    println!("EOF  null");

    if has_errors {
        process::exit(65)
    }
}

fn get_identifier(
    tokens: &mut std::iter::Peekable<std::str::Chars<'_>>,
    token: char,
    line_number: usize,
) -> Token {
    let mut word = token.to_string();

    while let Some(next) = tokens.peek().cloned() {
        match next {
            char if next.is_alphanumeric() || next == '_' => {
                tokens.next();
                word.push(char);
            }
            _ => return identifier_or_keyword(&word),
        }
    }

    identifier_or_keyword(&word)
}

fn identifier_or_keyword(word: &str) -> Token {
    KEYWORD_MAP
        .get(word)
        .cloned()
        .unwrap_or_else(|| Token::Identifier(word.to_string()))
}

fn get_numeric_token(
    tokens: &mut std::iter::Peekable<std::str::Chars<'_>>,
    token: char,
    line: usize,
) -> Token {
    let mut number = token.to_string();
    let mut decimal = false;

    while let Some(next) = tokens.peek().cloned() {
        match next {
            '.' => {
                if decimal {
                    return Token::ErrorString(number, 1);
                }

                decimal = true;
                tokens.next();
                number.push(next);
            }
            c if next.is_numeric() => {
                tokens.next();
                number.push(c);
            }
            _ => return parse_number(number, line),
        }
    }

    parse_number(number, line)
}

fn parse_number(string: String, line: usize) -> Token {
    let number = string.parse::<f64>();

    match number {
        Ok(number) => {
            let number = if number.fract() == 0.0 {
                format!("{:.1}", number)
            } else {
                format!("{}", number)
            };
            Token::Number(string, number)
        }
        Err(_) => Token::ErrorString(string, line),
    }
}

fn get_string_token(tokens: &mut std::iter::Peekable<std::str::Chars<'_>>, line: usize) -> Token {
    let mut string = String::new();
    while let Some(next) = tokens.peek().cloned() {
        match next {
            '"' => {
                tokens.next();
                return Token::String(string);
            }
            c => {
                tokens.next();
                string.push(c);
            }
        }
    }

    Token::ErrorString(string, line)
}

fn get_equal_token(
    tokens: &mut std::iter::Peekable<std::str::Chars<'_>>,
    if_equal_token: Token,
    token: Token,
) -> Token {
    match tokens.peek().copied() {
        Some('=') => {
            tokens.next();
            if_equal_token
        }
        _ => token,
    }
}
